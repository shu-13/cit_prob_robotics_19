{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率ロボティクス最終課題\n",
    "タイルワールドにおいて，エージェントの動きを強化学習のアルゴリズムを用いて生成する．\n",
    "課題の詳細は[ここ](https://lab.ueda.tech/?page=prob_robot_2019)を参照のこと\n",
    "\n",
    "### Defining the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        # U is up, D is down, L is left, R is right\n",
    "        # u_r is upright, u_l is upleft\n",
    "        # d_r is downright, d_l is downleft\n",
    "        self.actions = [\"U\", \"D\", \"L\", \"R\", \"u_r\", \"u_l\", \"d_r\", \"d_l\"]\n",
    "        self.pos = (0,0)\n",
    "\n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the environment\n",
    "Configuring the tile world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10\n",
    "\n",
    "class State:\n",
    "    def __init__(self,actions):\n",
    "        self.Q = {}\n",
    "        for a in actions:\n",
    "            self.Q[a] = 0.0\n",
    "        self.best_action = \"u_r\"\n",
    "        self.goal = False\n",
    "        \n",
    "    def set_goal(self,actions):\n",
    "        for a in actions:\n",
    "            self.Q[a] = 0.0\n",
    "        self.goal = True\n",
    "\n",
    "states = [[State(agent.actions) for i in range(size)] for j in range(size)]\n",
    "states[size-1][size-1].set_goal(agent.actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "The section for drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "textsize = 5\n",
    "\n",
    "def draw(mark_pos):\n",
    "    fig, ax = plt.subplots()\n",
    "    values = [[states[i][j].Q[states[i][j].best_action] for i in range(size)] for j in range(size)]\n",
    "    mp = ax.pcolor(values, cmap = plt.cm.YlOrRd, vmin = 0, vmax = 8)\n",
    "    ax.grid()\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_xticks(range(size+1), minor = False)\n",
    "    ax.set_yticks(range(size+1), minor = False)\n",
    "    \n",
    "    for x in range(len(values)):\n",
    "        for y in range(len(values[0])):\n",
    "            s = states[x][y]\n",
    "            plt.text(x+0.5, y+0.5, int(1000*s.Q[s.best_action])/1000, ha = 'center', va = 'center', size = textsize)\n",
    "            if states[x][y].goal:\n",
    "                plt.text(x+0.5, y+0.75, \"G\", ha = 'center', va = 'center', size = textsize)\n",
    "    \n",
    "    plt.text(agent.pos[0]+0.5, agent.pos[1]+0.25, \"AGENT\", ha = 'center', va = 'center', size = textsize)\n",
    "\n",
    "    if mark_pos == \"all\":\n",
    "        for x in range(size):\n",
    "            for y in range(size):\n",
    "                if states[x][y].goal: continue\n",
    "                plt.text(x+0.5, y+0.25, states[x][y].best_action, ha = 'center', va = 'center', size = textsize)\n",
    "    elif mark_pos != None:\n",
    "        s = states[mark_pos[0]][mark_pos[1]]\n",
    "        plt.text(mark_pos[0]+0.5, mark_pos[1]+0.25, s.best_action, ha = 'center', va = 'center', size = textsize)\n",
    "\n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "\n",
    "draw(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def state_transition(s_pos,a):\n",
    "    if random.uniform(0,1) < 0.1: #Return the same position at a 10% chance\n",
    "        return s_pos\n",
    "\n",
    "    x, y = s_pos\n",
    "    if a == \"U\": y += 1\n",
    "    elif a == \"D\": y -= 1\n",
    "    elif a == \"R\": x += 1\n",
    "    elif a == \"L\": x -= 1\n",
    "    elif a == \"u_r\": \n",
    "        if x < size-1 and y < size-1:\n",
    "            x += 1\n",
    "            y += 1\n",
    "    elif a == \"u_l\":\n",
    "        if x > 0 and y < size-1:\n",
    "            x -= 1\n",
    "            y += 1\n",
    "    elif a == \"d_r\":\n",
    "        if x < size-1 and y > 0:\n",
    "            x += 1\n",
    "            y -= 1\n",
    "    elif a == \"d_l\":\n",
    "        if x > 0 and y > 0:\n",
    "            x -= 1\n",
    "            y -= 1\n",
    "    \n",
    "    if x < 0: x = 0\n",
    "    elif x >= size: x = size-1\n",
    "    elif y < 0: y = 0\n",
    "    elif y >= size: y = size-1\n",
    "    \n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy (ε-greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy(s):\n",
    "    if random.uniform(0,1) < 0.1: #Choose something random ata 10% chance\n",
    "        return random.choice(agent.actions)\n",
    "\n",
    "    else:\n",
    "        best_a = None\n",
    "        best_q = 1000000000\n",
    "        for a in s.Q:\n",
    "            if best_q > s.Q[a]:\n",
    "                best_q = s.Q[a]\n",
    "                best_a = a\n",
    "        s.best_action = best_a\n",
    "        return best_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 's_best' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-60cdf182fc34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mone_trial_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-60cdf182fc34>\u001b[0m in \u001b[0;36mone_trial_q\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0ms_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-60cdf182fc34>\u001b[0m in \u001b[0;36mq_\u001b[0;34m(s_pos, a)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0ms_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_next\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_next\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" a:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_best_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" a':\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 's_best' referenced before assignment"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "gamma = 1.0\n",
    "\n",
    "def q_(s_pos,a):\n",
    "    s = states[s_pos[0]][s_pos[1]]\n",
    "    tmp = s.Q[a]\n",
    "    for i in range(10):\n",
    "        s_next_pos = state_transition(s_pos,a)\n",
    "        s_next = states[s_next_pos[0]][s_next_pos[1]]\n",
    "        a_next = e_greedy(s_next)\n",
    "        if s_next.Q[a_next] > tmp:\n",
    "            s_best = s_next\n",
    "            s_best_pos = s_next_pos\n",
    "            a_best = a_next\n",
    "        elif s_next.Q[a_next] <= tmp: tmp = s_next.Q[a_next]\n",
    "    \n",
    "    q = (1.0 - alpha) * s.Q[a] + alpha * (1.0 + gamma * s_best.Q[a_best])\n",
    "    \n",
    "    print(\"s:\" + str(s_pos) + \" a:\" + str(s_best_pos) + \" a':\" + a_best)\n",
    "    print(\"-----\")\n",
    "    return s_best_pos, a_best, q\n",
    "\n",
    "def one_trial_q():\n",
    "    agent.pos = (random.randrange(size),random.randrange(size))\n",
    "    a = e_greedy(states[agent.pos[0]][agent.pos[1]])\n",
    "    if states[agent.pos[0]][agent.pos[1]].goal:\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        s_best, a_best, q = q_(agent.pos, a)\n",
    "        states[agent.pos[0]][agent.pos[1]].Q[a] = q\n",
    "        agent.pos = s_best\n",
    "        a = a_best\n",
    "        if states[agent.pos[0]][agent.pos[1]].goal:\n",
    "            break\n",
    "\n",
    "for i in range(100):\n",
    "    one_trial_q()\n",
    "    draw(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
